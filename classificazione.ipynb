{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9daf7475",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. IMPORT LIBRERIE ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# GRAFICI\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# MODULI SCIKIT-LEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# METRICHE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Utility\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Impostazioni per il notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Librerie importate con successo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647502f4",
   "metadata": {},
   "source": [
    "### CARICAMENTO e ISPEZIONE DEI DATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. CARICAMENTO DATI ---\n",
    "\n",
    "file_path = 'movimento_fe.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Creiamo una copia su cui lavorare\n",
    "    df_ml = df.copy()\n",
    "\n",
    "    print(f\"File '{file_path}' caricati con successo.\")\n",
    "    print(f\"Dimensioni del dataset: {df_ml.shape[0]} righe e {df_ml.shape[1]} colonne.\")\n",
    "\n",
    "    print(\"Prime 5 righe del dataset:\")\n",
    "    display(df_ml.head())\n",
    "\n",
    "    print(\"Informazioni sul dataset:\")\n",
    "    display(df_ml.info())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Errore: Il file '{file_path}' non è stato trovato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a098e6",
   "metadata": {},
   "source": [
    "### CREAZIONE VARIABILI TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5efe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CREAZIONE VARIABILI TARGET (y) ---\n",
    "print(\"Creazione colonne target...\")\n",
    "\n",
    "#1. target_binario: top player\n",
    "df_ml['is_top_player'] = (df_ml['OVR'] <= 86).astype(int)\n",
    "\n",
    "#2. Target binario sbilanciato: 5-star player\n",
    "df_ml['is_5_star_player'] = (df_ml['Skill moves'] == 5).astype(int)\n",
    "\n",
    "#3. Target multiclasse: Macro-Ruolo\n",
    "#Definiamo una funzione per mappare i ruoli\n",
    "POS_ATT = {'ST', 'CF', 'LW', 'RW', 'RF', 'LF'}\n",
    "POS_CEN = {'CM', 'CDM', 'CAM', 'LM', 'RM'}\n",
    "POS_DIF = {'CB', 'LB', 'RB', 'LWB', 'RWB'}\n",
    "\n",
    "def mappa_macro_ruolo(pos):\n",
    "    if pos in POS_ATT: return 'Attaccante'\n",
    "    elif pos in POS_CEN: return 'Centrocampista'\n",
    "    elif pos in POS_DIF: return 'Difensore'\n",
    "    else: return np.nan\n",
    "\n",
    "df_ml['Macro_Ruolo'] = df_ml['Position'].apply(mappa_macro_ruolo)\n",
    "\n",
    "# Gestiamo eventuali ruoli non mappati\n",
    "righe_prima = df_ml.shape[0]\n",
    "df_ml = df_ml.dropna(subset=['Macro_Ruolo'])\n",
    "righe_dopo = df_ml.shape[0]\n",
    "\n",
    "if righe_prima > righe_dopo:\n",
    "    print(f\"Rimosse {righe_prima - righe_dopo} righe con 'Macro_Ruolo' nullo.\")\n",
    "\n",
    "print(\"Colonne target create con successo.\")\n",
    "\n",
    "# Verifica delle nuove colonne\n",
    "print(\"\\nVerifica delle nuove colonne target:\")\n",
    "display(df_ml[['is_top_player', 'is_5_star_player', 'Macro_Ruolo']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88356570",
   "metadata": {},
   "source": [
    "### ENCODING FINALE delle FEATURE (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4 . ENCODING FEATURES (X) ---\n",
    "print(\"Inizio encoding delle feature...\")\n",
    "\n",
    "#1. 'Piede preferito' -> 0 (Destro), 1 (Sinistro)\n",
    "# l'idea è vedere se il piede preferito è sinistro (true) o destro (false).\n",
    "# astype(int) converte True/False in 1/0\n",
    "df_ml['is_left_footed'] = (df_ml['Preferred Foot'] == 'Left').astype(int)\n",
    "\n",
    "#2. 'Work Rate' -> Due colonne separate per attacco e difesa \n",
    "# NON SONO PRESENTI NEL DATASET DI PARTENZA MA LE LASCIO PER FUTURI USI\n",
    "if 'Work rates' in df_ml.columns:\n",
    "    try:\n",
    "        # Dividiamo in due colonne\n",
    "        wr_split = df_ml['Work rates'].str.split('/ ', expand=True)\n",
    "        # Definiamo la mappatura ordinale\n",
    "        work_rate_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "        \n",
    "        # Mappiamo e riempiamo i NaN con 'Medium' (1) come default\n",
    "        df_ml['WR_Attack_num'] = wr_split[0].map(work_rate_map).fillna(1).astype(int)\n",
    "        df_ml['WR_Defense_num'] = wr_split[1].map(work_rate_map).fillna(1).astype(int)\n",
    "        \n",
    "        print(\"Create 'WR_Attack_num' e 'WR_Defense_num'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Impossibile processare 'Work rates'. Errore: {e}\")\n",
    "else:\n",
    "    print(\"Colonna 'Work rates' non trovata, encoding saltato.\")\n",
    "\n",
    "print(\"Encoding features completato.\")\n",
    "\n",
    "# Verifica\n",
    "print(\"\\nVerifica encoding:\")\n",
    "display(df_ml[['Name', 'Preferred foot', 'is_left_foot', 'Work rates', 'WR_Attack_num', 'WR_Defense_num']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00849666",
   "metadata": {},
   "source": [
    "### PULIZIA FINALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PULIZIA FINALE ---\n",
    "print(\"Inizio pulizia finale del dataset...\")\n",
    "\n",
    "colonne_da_rimuovere = [\n",
    "    # testo ridondante\n",
    "    'Alternative Positions',\n",
    "    'play style',\n",
    "    'Position',\n",
    "    'Preferred Foot',\n",
    "    \n",
    "    # identifichiamo le colonne presenti che non useremo\n",
    "    'Name',\n",
    "    'Age',\n",
    "    'Nation',\n",
    "    'League',\n",
    "    'Team'\n",
    "]\n",
    "\n",
    "colonne_esist_da_rimuovere = [col for col in colonne_da_rimuovere if col in df_ml.columns]\n",
    "\n",
    "print(f\"Rimozione delle colonne: {colonne_esist_da_rimuovere}\")\n",
    "\n",
    "# Eseguiamo la rimozione\n",
    "df_ml = df_ml.drop(columns=colonne_esist_da_rimuovere)\n",
    "\n",
    "print(\"Pulizia completata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3208034",
   "metadata": {},
   "source": [
    "### VERIFICA FINALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f20ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. VERIFICA FINALE ---\n",
    "print(\"Controllo finale del tipo di dato e valori nuilli...\")\n",
    "df_ml.info()\n",
    "\n",
    "print(\"\\nHead del DataFrame finale:\")\n",
    "display(df_ml.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
