{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ca93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Sopprime i warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Avvio dell'analisi DBSCAN...\")\n",
    "\n",
    "# Carica il dataset\n",
    "file_path = 'data/puliti/movimento_fe.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- 1. Preparazione delle \"Etichette Vere\" (per la valutazione) ---\n",
    "    df['Primary_Position'] = df['Position'].apply(lambda x: x.split(',')[0].strip() if pd.notnull(x) else 'Unknown')\n",
    "    df = df[df['Primary_Position'] != 'Unknown']\n",
    "    true_labels = df['Primary_Position']\n",
    "    k_true = true_labels.nunique()\n",
    "    print(f\"Etichette vere ('Primary_Position') caricate. Ci sono {k_true} ruoli unici.\")\n",
    "\n",
    "    # --- 2. Preparazione delle \"Features\" (X) ---\n",
    "    X = df.select_dtypes(include='number').copy()\n",
    "    features_used = X.columns.tolist()\n",
    "    print(f\"Preprocessing di {len(features_used)} features numeriche...\")\n",
    "    \n",
    "    # --- 3. Preprocessing (Imputazione e Scaling) ---\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    print(\"Dati imputati e scalati pronti.\")\n",
    "\n",
    "    # --- 4. Analisi per trovare 'eps' e 'min_samples' ---\n",
    "    D = X_scaled.shape[1]\n",
    "    min_samples = 2 * D\n",
    "    print(f\"Dimensioni (features): {D}. Imposto min_samples = {min_samples}\")\n",
    "\n",
    "    print(\"Calcolo delle distanze dei vicini (NearestNeighbors)...\")\n",
    "    nn = NearestNeighbors(n_neighbors=min_samples, n_jobs=-1)\n",
    "    nn.fit(X_scaled)\n",
    "    distances, indices = nn.kneighbors(X_scaled)\n",
    "    \n",
    "    kth_distances = distances[:, min_samples - 1]\n",
    "    kth_distances_sorted = np.sort(kth_distances)\n",
    "\n",
    "    # --- 5. Trovare 'eps' (Metodo alternativo) ---\n",
    "    # Dato che l'installazione di 'kneed' è fallita,\n",
    "    # usiamo un'euristica comune: il 95° percentile.\n",
    "    chosen_eps = np.percentile(kth_distances_sorted, 95)\n",
    "    print(f\"Valore 'eps' trovato (euristica 95° percentile): {chosen_eps:.4f}\")\n",
    "\n",
    "    # --- 6. Salvare il grafico del gomito ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(kth_distances_sorted)\n",
    "    plt.hlines(chosen_eps, xmin=0, xmax=len(kth_distances_sorted), linestyles='--', colors='r', label=f'eps (95° percentile)={chosen_eps:.4f}')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Punti (ordinati per distanza)\")\n",
    "    plt.ylabel(f\"Distanza dal {min_samples}-esimo vicino\")\n",
    "    plt.title(\"Analisi 'Elbow' per DBSCAN (k-distance plot)\")\n",
    "    plt.savefig('dbscan_eps_plot.png')\n",
    "    print(\"Grafico 'dbscan_eps_plot.png' salvato.\")\n",
    "\n",
    "    # --- 7. Eseguire DBSCAN ---\n",
    "    print(f\"Esecuzione di DBSCAN in corso (eps={chosen_eps:.4f}, min_samples={min_samples})...\")\n",
    "    dbscan = DBSCAN(eps=chosen_eps, min_samples=min_samples, n_jobs=-1)\n",
    "    cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "    # --- 8. Analisi Risultati DBSCAN ---\n",
    "    n_clusters_ = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    n_noise_ = list(cluster_labels).count(-1)\n",
    "    \n",
    "    print(f\"\\n--- Risultati DBSCAN ---\")\n",
    "    print(f\"Numero di cluster trovati (escluso rumore): {n_clusters_}\")\n",
    "    print(f\"Numero di punti 'rumore' (etichetta -1): {n_noise_} (su {len(df)} totali)\")\n",
    "\n",
    "    # --- 9. Valutazione e Confronto ---\n",
    "    ari_score = metrics.adjusted_rand_score(true_labels, cluster_labels)\n",
    "    nmi_score = metrics.normalized_mutual_info_score(true_labels, cluster_labels)\n",
    "    \n",
    "    print(\"\\n--- Metriche di Valutazione (vs Etichette Reali) ---\")\n",
    "    print(f\"Adjusted Rand Index (ARI): {ari_score:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {nmi_score:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Confronto con KMeans (k=11, tutte le features) ---\")\n",
    "    print(\"KMeans ARI (precedente): 0.2491\")\n",
    "    print(\"KMeans NMI (precedente): 0.3697\")\n",
    "    \n",
    "    if ari_score > 0.2491:\n",
    "        print(\"Risultato: DBSCAN è più allineato ai ruoli.\")\n",
    "    else:\n",
    "        print(\"Risultato: KMeans (forzato a 11 cluster) era più allineato ai 11 ruoli.\")\n",
    "\n",
    "    # --- 10. Matrice di Contingenza ---\n",
    "    df['DBSCAN_Cluster'] = cluster_labels\n",
    "    contingency_matrix_dbscan = pd.crosstab(df['Primary_Position'], df['DBSCAN_Cluster'])\n",
    "    print(\"\\n--- Matrice di Contingenza DBSCAN (Righe: Posizioni Vere, Colonne: Cluster Trovati) ---\")\n",
    "    print(\"La colonna '-1' rappresenta il 'rumore' (outlier)\")\n",
    "    print(contingency_matrix_dbscan)\n",
    "    contingency_matrix_dbscan.to_csv('contingency_matrix_dbscan.csv')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Errore: File '{file_path}' non trovato.\")\n",
    "except Exception as e:\n",
    "    print(f\"Si è verificato un errore: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
